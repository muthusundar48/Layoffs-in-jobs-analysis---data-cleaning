# Layoffs-in-jobs-analysis--data-cleaning [Click here](https://github.com/muthusundar48/Layoffs-in-jobs-analysis---data-cleaning/blob/main/queries.md)
This project is to analyze the layoffs happened in various companies in the past few years

## 📌 Project Overview
This project focuses on **cleaning and preparing raw data** for better analysis and visualization. The dataset contains inconsistencies such as missing values, incorrect formatting, duplicate records, and redundant data, which are cleaned using **SQL and Excel**.

## 🚀 Skills & Tools Used
- **SQL** (MySQL)
- **Data Cleaning Techniques** (Handling missing values, duplicates, formatting)
- **Normalization & Standardization**

## 📂 Dataset Details
- **Dataset Name:** [layoffs.csv]
- **Source:** [Kaggle]
- **Size:** [2362*9]
- **Description:** [This dataset contains data about the number layoffs happened in various companies and their industry from time to time and the result gained due to the layoffs]

## 🔄 Data Cleaning Steps
1. **Removed Duplicates:** Eliminated redundant rows.
2. **Handled Missing Values:** Used appropriate methods (e.g., imputation, deletion).
3. **Standardized Data Formats:** Ensured consistent date formats, text casing, etc.
4. **Fixed Incorrect Entries:** Identified and corrected null or blank data.
5. **Normalized Columns:** Split concatenated data and ensured proper structuring.
6. **Final Data Export:** Cleaned data stored in a structured format for analysis.

## 📊 Final Output
- A **cleaned dataset** ready for **analysis and visualization**.
- Improved **data accuracy and consistency**.

## 📁 Project Files
- `layoffs.csv` → Uncleaned original dataset
- `cleaned_layoffs.csv` → Final cleaned dataset
- `queries.md` → SQL queries used for cleaning

## 🔍 How to Use This Project
1. Clone this repository:
